{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d43879c-758e-4b37-b93b-392750c4d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595c1b43-3a80-42c4-ab02-8bc823e8899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas got an error, and resolved using opening the jupyter notebook with anaconda navigator instead\n",
    "# of powershell prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa494e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdirectory on FTP Server: /annual/kl/historical/\n"
     ]
    }
   ],
   "source": [
    "# The topic of interest\n",
    "topic_dir = \"/annual/kl/historical/\"\n",
    "print(\"Subdirectory on FTP Server:\", topic_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6b02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_ftp_dir         = \"../data/original/DWD/\"      # Local directory to store local ftp data copies, the local data source or input data. \n",
    "local_ftp_dir         = \"data/original/DWD/\"      # Local directory to store local ftp data copies, the local data source or input data. \n",
    "local_ftp_station_dir = local_ftp_dir + topic_dir # Local directory where local station info is located\n",
    "local_ftp_ts_dir      = local_ftp_dir + topic_dir # Local directory where time series downloaded from ftp are located\n",
    "\n",
    "#local_generated_dir   = \"../data/generated/DWD/\" # The generated of derived data in contrast to local_ftp_dir\n",
    "local_generated_dir   = \"data/generated/DWD/\" # The generated of derived data in contrast to local_ftp_dir\n",
    "local_station_dir     = local_generated_dir + topic_dir # Derived station data, i.e. the CSV file\n",
    "local_ts_merged_dir   = local_generated_dir + topic_dir # Parallel merged time series, wide data frame with one TS per column\n",
    "local_ts_appended_dir = local_generated_dir + topic_dir # Serially appended time series, long data frame for QGIS TimeManager Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591b837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(local_ftp_dir,exist_ok = True) # it does not complain if the dir already exists.\n",
    "os.makedirs(local_ftp_station_dir,exist_ok = True)\n",
    "os.makedirs(local_ftp_ts_dir,exist_ok = True)\n",
    "\n",
    "os.makedirs(local_generated_dir,exist_ok = True)\n",
    "os.makedirs(local_station_dir,exist_ok = True)\n",
    "os.makedirs(local_ts_merged_dir,exist_ok = True)\n",
    "os.makedirs(local_ts_appended_dir,exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3246dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/original/DWD/\n",
      "data/original/DWD//annual/kl/historical/\n",
      "data/original/DWD//annual/kl/historical/\n",
      "\n",
      "data/generated/DWD/\n",
      "data/generated/DWD//annual/kl/historical/\n",
      "data/generated/DWD//annual/kl/historical/\n",
      "data/generated/DWD//annual/kl/historical/\n"
     ]
    }
   ],
   "source": [
    "# check if directories are rightly generated\n",
    "print(local_ftp_dir)\n",
    "print(local_ftp_station_dir)\n",
    "print(local_ftp_ts_dir)\n",
    "print()\n",
    "print(local_generated_dir)\n",
    "print(local_station_dir)\n",
    "print(local_ts_merged_dir)\n",
    "print(local_ts_appended_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba506b49",
   "metadata": {},
   "source": [
    "FTP Connection\n",
    "\n",
    "Connection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad68fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"opendata.dwd.de\"\n",
    "user   = \"anonymous\"\n",
    "passwd = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc2cdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute FTP directory path with data of concern: /climate_environment/CDC/observations_germany/climate//annual/kl/historical/\n"
     ]
    }
   ],
   "source": [
    "# This is the search pattern common to ALL station description file names \n",
    "station_desc_pattern = \"_Beschreibung_Stationen.txt\"\n",
    "\n",
    "# Below this directory tree node all climate data are stored.\n",
    "ftp_climate_data_dir = \"/climate_environment/CDC/observations_germany/climate/\"\n",
    "\n",
    "# The absolute ftp directory with the data (topic) of concern\n",
    "ftp_dir =  ftp_climate_data_dir + topic_dir\n",
    "print(\"Absolute FTP directory path with data of concern:\", ftp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1cf4f",
   "metadata": {},
   "source": [
    "### FTP Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023dc87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 Login successful.\n"
     ]
    }
   ],
   "source": [
    "import ftplib\n",
    "ftp = ftplib.FTP(server)\n",
    "res = ftp.login(user=user, passwd = passwd)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f138a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = ftp.cwd(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676f3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ftp.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b1cf",
   "metadata": {},
   "source": [
    "### FTP Grab File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4906afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabFile(ftpfullname,localfullname):\n",
    "    try:\n",
    "        ret = ftp.cwd(\".\") # A dummy action to check the connection and to provoke an exception if necessary.\n",
    "        localfile = open(localfullname, 'wb')\n",
    "        ftp.retrbinary('RETR ' + ftpfullname, localfile.write, 1024)\n",
    "        localfile.close()\n",
    "    \n",
    "    except ftplib.error_perm:\n",
    "        print(\"FTP ERROR. Operation not permitted. File not found?\")\n",
    "\n",
    "    except ftplib.error_temp:\n",
    "        print(\"FTP ERROR. Timeout.\")\n",
    "\n",
    "    except ConnectionAbortedError:\n",
    "        print(\"FTP ERROR. Connection aborted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee2311",
   "metadata": {},
   "source": [
    "## Generate Pandas Dataframe from FTP Directory Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66d0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_from_ftp_dir_listing(ftp, ftpdir):\n",
    "    lines = []\n",
    "    flist = []\n",
    "    try:    \n",
    "        res = ftp.retrlines(\"LIST \"+ftpdir, lines.append)\n",
    "    except:\n",
    "        print(\"Error: ftp.retrlines() failed. ftp timeout? Reconnect!\")\n",
    "        return\n",
    "        \n",
    "    if len(lines) == 0:\n",
    "        print(\"Error: ftp dir is empty\")\n",
    "        return\n",
    "    \n",
    "    for line in lines:\n",
    "#        print(line)\n",
    "        [ftype, fsize, fname] = [line[0:1], int(line[31:42]), line[56:]]\n",
    "#        itemlist = [line[0:1], int(line[31:42]), line[56:]]\n",
    "#        flist.append(itemlist)\n",
    "        \n",
    "        fext = os.path.splitext(fname)[-1]\n",
    "        \n",
    "        if fext == \".zip\":\n",
    "            station_id = int(fname.split(\"_\")[2])\n",
    "        else:\n",
    "            station_id = -1 \n",
    "        \n",
    "        flist.append([station_id, fname, fext, fsize, ftype])\n",
    "        \n",
    "        \n",
    "\n",
    "    df_ftpdir = pd.DataFrame(flist,columns=[\"station_id\", \"name\", \"ext\", \"size\", \"type\"])\n",
    "    return(df_ftpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5caf24a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ftp.retrlines() failed. ftp timeout? Reconnect!\n"
     ]
    }
   ],
   "source": [
    "df_ftpdir = gen_df_from_ftp_dir_listing(ftp, ftp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4459dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_ftpdir\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df_ftpdir.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67f85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
